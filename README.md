# ğŸª Magic Mirror - Interactive Avatar System

A modern, cloud-native avatar animation platform built with **Deno + TypeScript**. Create interactive 3D characters that talk, listen, and respond with emotion-aware AI.

**Tech Stack**: Deno ğŸ¦• | Oak Framework | TypeScript | Three.js | NVIDIA Audio2Face | face-api.js | OpenAI/Mammouth.ai

---

## âœ¨ Features

### ğŸ¬ Core Avatar Engine

- **Real-time Animation**: NVIDIA Audio2Face gRPC service for mouth sync
- **3D Models**: FBX avatars (Lynx, Frank, Mirror) rendered with Three.js
- **Blendshape Control**: 100+ facial expressions and emotions
- **Multi-Model Support**: Mark v2.3, Claire v2.3, James v2.3 with YAML configs

### ğŸ¤ Voice Conversation

- **Speech Recognition**: OpenAI Whisper STT (speech-to-text)
- **AI Responses**: ChatGPT via OpenAI or cheaper Mammouth.ai
- **Text-to-Speech**: OpenAI TTS (text-to-speech) with natural voices
- **Full Pipeline**: Microphone â†’ STT â†’ AI Chat â†’ TTS â†’ Avatar Animation

### ğŸ˜Š Emotion Detection

- **Real-time Webcam Analysis**: face-api.js emotion recognition
- **7 Emotion States**: Happy, Sad, Angry, Fearful, Disgusted, Surprised, Neutral
- **Smart Greetings**: Personalized responses based on detected emotion
- **Live Visualization**: Detection box + confidence scores on canvas

### ğŸ’° Cost Optimization

- **Default**: Uses OpenAI for full feature set
- **Budget Mode**: Switch to Mammouth.ai for 70-80% cheaper chat (optional)
- **Environment Config**: Easy provider switching via `.env`

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Prerequisites

- **Deno** 1.40+ ([install](https://deno.com))
- **OpenAI API Key** for voice features ([get one](https://platform.openai.com/api-keys))
- Modern browser with WebRTC support

### 2ï¸âƒ£ Setup

```bash
# Clone/extract project
cd Magic_Mirror

# Copy environment template
cp .env.example .env

# Edit .env and add your keys:
# OPENAI_API_KEY=sk-...your-key...
nano .env
```

### 3ï¸âƒ£ Start Server

```bash
deno task dev
```

Output:

```
ğŸš€ Oak server running at http://localhost:1234
ğŸ¤ Voice conversation: âœ… enabled
ğŸ“· Emotion detection: âœ… ready
```

### 4ï¸âƒ£ Access Features

| Feature             | URL                             | Description                |
| ------------------- | ------------------------------- | -------------------------- |
| **Production Mode** | http://localhost:1234/prod.html | Landing page (no settings) |
| **Voice Chat**      | http://localhost:1234/talk      | Speech + emotion UI        |
| **Face Viewer**     | http://localhost:1234/face      | 3D avatar display          |
| **Settings**        | http://localhost:1234/settings  | Configuration panel        |
| **Debug**           | http://localhost:1234/debug     | Dev tools                  |

---

## ğŸ“ Project Structure

```
Magic_Mirror/
â”œâ”€â”€ ğŸ“ src/                          # TypeScript backend (Deno)
â”‚   â”œâ”€â”€ server.ts                    # Oak HTTP server + routes
â”‚   â”œâ”€â”€ openai.ts                    # AI provider abstraction
â”‚   â”œâ”€â”€ config.ts                    # Environment + .env loader
â”‚   â”œâ”€â”€ blendshape-utils.ts          # Facial expression engine
â”‚   â””â”€â”€ ğŸ“ nvidia/                   # Audio2Face integration
â”‚       â”œâ”€â”€ index.ts                 # Module exports
â”‚       â”œâ”€â”€ constants.ts             # PCM16, timing config
â”‚       â”œâ”€â”€ models.ts                # Mark/Claire/James configs
â”‚       â”œâ”€â”€ audio-processor.ts       # Audio normalization
â”‚       â”œâ”€â”€ config-loader.ts         # YAML parser
â”‚       â””â”€â”€ service.ts               # A2F service layer
â”‚
â”œâ”€â”€ ğŸ“ public/                       # Frontend (HTML/CSS/JS)
â”‚   â”œâ”€â”€ index.html                   # Home page
â”‚   â”œâ”€â”€ face.html                    # Avatar viewer
â”‚   â”œâ”€â”€ talk.html                    # Voice conversation UI â­
â”‚   â”œâ”€â”€ settings.html                # Config panel
â”‚   â”œâ”€â”€ main.js                      # Three.js + FBX loader
â”‚   â”œâ”€â”€ voice-conversation.js        # Microphone capture + API
â”‚   â”œâ”€â”€ emotion-detector.js          # Webcam emotion recognition â­
â”‚   â”œâ”€â”€ blendshape-drivers.js        # Blendshape animations
â”‚   â”œâ”€â”€ styles.css                   # Main styles
â”‚   â””â”€â”€ audio-worklets/              # Web Audio API processors
â”‚
â”œâ”€â”€ ğŸ“ characters/                   # 3D Avatar Models (FBX)
â”‚   â”œâ”€â”€ frank/
â”‚   â”œâ”€â”€ mirror/
â”‚   â””â”€â”€ lynq/                        # Default avatar (Lynx bobcat)
â”‚
â”œâ”€â”€ ğŸ“ nvidia/                       # NVIDIA Audio2Face config
â”‚   â”œâ”€â”€ ğŸ“ configs/                  # Model YAML files
â”‚   â”‚   â”œâ”€â”€ mark_v2.3.yml
â”‚   â”‚   â”œâ”€â”€ claire_v2.3.yml
â”‚   â”‚   â””â”€â”€ james_v2.3.yml
â”‚   â””â”€â”€ ğŸ“ protos/                   # gRPC protocol buffers
â”‚
â”œâ”€â”€ deno.json                        # Deno config + tasks
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ .env.docker                      # Docker environment template
â”œâ”€â”€ Dockerfile                       # Docker image definition
â”œâ”€â”€ docker-compose.yml               # Docker compose config
â””â”€â”€ README.md                        # This file

ğŸ“š Documentation:
â”œâ”€â”€ VOICE_SETUP.md                   # Voice conversation guide
â”œâ”€â”€ CAMERA_SETUP.md                  # Emotion detection setup
â”œâ”€â”€ ARCHITECTURE.md                  # Technical architecture
â”œâ”€â”€ TROUBLESHOOTING.md               # Problem solving
â””â”€â”€ docs/DOCKER_DEPLOYMENT.md        # Docker production deployment
```

---

## ğŸ³ Docker Deployment (Production)

### One-Command Deployment

```bash
# 1. Configure environment
cp .env.docker .env.prod
echo "OPENAI_API_KEY=sk-..." >> .env.prod

# 2. Start with Docker Compose
docker-compose up -d

# 3. Access production interface
http://localhost:1234/prod.html
```

**Features:**

- âœ… Minimal landing page (no settings UI)
- âœ… Direct voice conversation interface
- âœ… Emotion detection enabled
- âœ… 3D avatar with real-time animation
- âœ… Resource limits & security hardening
- âœ… Health checks & auto-restart

**See [docs/DOCKER_DEPLOYMENT.md](./docs/DOCKER_DEPLOYMENT.md) for:**

- Kubernetes & Docker Swarm setup
- Monitoring & logging
- Performance tuning
- Production best practices

---

## ğŸ¯ How It Works

### ğŸ¤ Voice Conversation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Microphone â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ WebAudio API
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Whisper (OpenAI) â”‚â”€â”€â”€â”€â–¶â”‚   User Text â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚
       â”‚                        â–¼
       â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚ ChatGPT/Claude â”‚ (AI Response)
       â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚
       â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TTS (OpenAI)   â”‚â”€â”€â”€â”€â–¶â”‚  MP3 Audio File â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚
       â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio2Face (NVIDIA gRPC)        â”‚
â”‚  Generates blendshape animation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Three.js Avatar                 â”‚
â”‚  Speaks with mouth sync          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ˜Š Emotion Detection Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webcam    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  face-api.js     â”‚
â”‚  TinyFaceDetectorâ”‚ (Detects face)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FaceExpressionNetâ”‚ (7 emotions)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Emotion: Happy (92% confidence)  â”‚
â”‚ Personalized greeting generated  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Configuration

### Environment Variables (`.env`)

```bash
# Required: OpenAI API key
OPENAI_API_KEY=sk-...

# Optional: Server port (default: 1234)
PORT=1234

# Optional: AI Model (default: gpt-4o-mini)
OPENAI_MODEL=gpt-4o-mini

# Optional: TTS voice (default: alloy)
OPENAI_VOICE=alloy
```

### Switch to Mammouth.ai (Optional)

For 70-80% cheaper chat completions:

```bash
# In .env, add:
MAMMOUTH_API_KEY=your-key-here

# Note: Whisper STT and TTS remain on OpenAI (not available on Mammouth)
```

---

## ğŸ“– Documentation Map

```
ğŸ“š docs/                           All documentation files
â”œâ”€â”€ VOICE_SETUP.md                 Voice conversation guide
â”œâ”€â”€ CAMERA_SETUP.md                Emotion detection setup
â”œâ”€â”€ ARCHITECTURE.md                System design & data flows
â”œâ”€â”€ DOCKER_DEPLOYMENT.md           Production deployment
â”œâ”€â”€ TROUBLESHOOTING.md             Problem solving
â”œâ”€â”€ realtime-audio-to-a2f.md       Audio pipeline details
â”œâ”€â”€ DENO_README.md                 Deno configuration
â””â”€â”€ CLEANUP.md                     Project cleanup guide

ğŸš€ Quick Links:
â”œâ”€â”€ Voice Chat UI:                 http://localhost:1234/talk
â”œâ”€â”€ Debug Console:                 http://localhost:1234/debug
â”œâ”€â”€ Production Mode:               http://localhost:1234/prod.html
â””â”€â”€ Avatar Viewer:                 http://localhost:1234/face
```

---

## ğŸ“š Detailed Guides

- ğŸ¤ **[Voice Conversation Setup](./docs/VOICE_SETUP.md)** - Complete voice feature guide
- ğŸ“· **[Camera & Emotion Detection](./docs/CAMERA_SETUP.md)** - Webcam setup & troubleshooting
- ğŸ—ï¸ **[System Architecture](./docs/ARCHITECTURE.md)** - Technical deep dive & data flows
- ğŸ”Š **[Audio Processing](./docs/realtime-audio-to-a2f.md)** - Real-time audio to blendshapes
- ğŸ³ **[Docker Deployment](./docs/DOCKER_DEPLOYMENT.md)** - Production deployment guide
- ğŸ”§ **[Troubleshooting](./docs/TROUBLESHOOTING.md)** - Problem solving guide
- ğŸ“– **[Deno Setup](./docs/DENO_README.md)** - Deno-specific configuration

# Optional: Mammouth.ai API key (for cheaper chat)

MAMMOUTH_API_KEY=...

# Optional: Nvidia Audio2Face endpoint

NVIDIA_A2F_ENDPOINT=grpc.nvcf.nvidia.com:443

### Switch to Mammouth.ai (Optional)

For 70-80% cheaper chat completions:

```bash
# In .env, add:
MAMMOUTH_API_KEY=your-key-here

# Note: Whisper STT and TTS remain on OpenAI (not available on Mammouth)
```

---

## ğŸ“Š API Endpoints

### Public Pages

- `GET /` â†’ Home page
- `GET /face` â†’ Avatar viewer
- `GET /talk` â†’ Voice conversation UI with emotion detection
- `GET /settings` â†’ Settings panel
- `GET /debug` â†’ Debug tools

### API Routes

```
GET /api/characters
  Returns: [{ name: "Lynx", url: "/characters/lynq/lynx_bobcat_01.fbx" }, ...]

GET /api/models
  Returns: [{ name: "Mark v2.3", config: {...} }, ...]

POST /api/process-audio
  Body: { audio: "base64_pcm16", character: "mark_v2_3" }
  Returns: { blendshapes: [...], duration: 2.5 }

POST /api/conversation
  Body: { audio: "base64_wav", systemPrompt?: "...", character?: "mark_v2_3" }
  Returns: { userMessage: "...", assistantMessage: "...", audio: "base64_mp3" }
```

---

## ğŸ’» Development

### Run in Development Mode

```bash
deno task dev
```

### View Deno Tasks

```bash
deno task
```

### Build for Production

```bash
deno compile --allow-net --allow-read --allow-env src/server.ts
```

### Debug Logs

```bash
# In server.ts, logs show:
# - API requests
# - OpenAI/Mammouth API calls
# - Emotion detection events
# - Audio processing stats
```

---

## ğŸ¨ Customization

### Change Default Avatar

Edit `/public/face.js`:

```javascript
const MIRROR_URL = "/characters/lynq/lynx_bobcat_01.fbx"; // Change this
```

### Change Character Voice

Edit `src/openai.ts`:

```typescript
voice: "nova"; // Options: alloy, echo, fable, onyx, nova, shimmer
```

### Change AI Model

Edit `src/openai.ts`:

```typescript
model: "gpt-4"; // Options: gpt-4, gpt-4o, gpt-3.5-turbo, etc.
```

### Add Custom Emotion Greeting

Edit `public/emotion-detector.js`:

```javascript
const greetings = {
  happy: "Du siehst glÃ¼cklich aus! SchÃ¶n, dass es dir gut geht!",
  // Add more...
};
```

---

## ğŸ› Troubleshooting

| Problem                         | Solution                                               |
| ------------------------------- | ------------------------------------------------------ |
| "Port already in use"           | `lsof -ti:1234 \| xargs kill -9` then restart          |
| "OpenAI API key not configured" | Add `OPENAI_API_KEY` to `.env`                         |
| "Microphone access denied"      | Allow mic in browser permissions â†’ Reload page         |
| "No emotion detection"          | Check browser console; face-api.js needs camera access |
| "Avatar not animating"          | Verify Audio2Face endpoint is reachable                |
| "Slow response times"           | Check OpenAI rate limits; consider Mammouth.ai         |

---

## ğŸš€ Deployment

### Deploy to Deno Deploy

```bash
deno publish
```

### Deploy to Docker

```dockerfile
FROM denoland/deno:latest
COPY . /app
WORKDIR /app
RUN deno cache src/server.ts
CMD ["deno", "run", "--allow-net", "--allow-read", "--allow-env", "src/server.ts"]
```

---

## ğŸ“„ License

This project integrates with NVIDIA Audio2Face and OpenAI services. Refer to their terms of service for usage restrictions.

---

## ğŸ¤ Contributing

Improvements welcome! Areas for enhancement:

- [ ] Additional avatar models
- [ ] More emotion states
- [ ] Alternative AI providers (Claude, Cohere, etc.)
- [ ] Multi-language support
- [ ] Recording conversations
- [ ] Analytics & metrics

---

**Made with â¤ï¸ using Deno, TypeScript, and modern web APIs**

## ğŸŒ API Endpoints

### `GET /api/characters`

List available FBX models

### `GET /api/models`

List supported Audio2Face models

### `POST /api/process-audio`

Process audio with Audio2Face

## ğŸ“ For More Details

See [docs/DENO_README.md](./docs/DENO_README.md) for complete documentation.

## Integrating OpenAI Realtime audio with NVIDIA Audio2Face

If you are wiring OpenAIâ€™s Realtime API into NVIDIA Audio2Face (A2F), follow the step-by-step guide in [`docs/realtime-audio-to-a2f.md`](docs/realtime-audio-to-a2f.md). It covers enabling audio output from the Realtime session, capturing the correct WebRTC stream, resampling to 16 kHz PCM16, chunking uploads for A2F, and the telemetry you need to confirm the avatar is actually receiving speech audio.
